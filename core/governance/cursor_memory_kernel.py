"""
Cursor Memory Kernel - Session Memory & TODO Tracking

Wraps l9.workflow_todo_kernel.v2.yaml into executable Python.
Provides session-start memory loading, TODO tracking, and confidence logic.

Factory: create_cursor_memory_kernel()

Config: .cursor/cursor-memory/l9.workflow_todo_kernel.v2.yaml
"""

from __future__ import annotations

import os
import subprocess
import json
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Optional
import yaml

import structlog

logger = structlog.get_logger(__name__)

# =============================================================================
# Configuration
# =============================================================================

KERNEL_CONFIG_PATH = Path(".cursor/cursor-memory/l9.workflow_todo_kernel.v2.yaml")

# PostgreSQL
DOCKER_POSTGRES = "l9-postgres"
DATABASE = "l9_memory"
DB_USER = "postgres"

# Neo4j
DOCKER_NEO4J = "l9-neo4j"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "FVmgaD1diPcz41zRbYLLP0UzyGvAi4E"  # TODO: Move to env

# Redis
DOCKER_REDIS = "l9-redis"

# =============================================================================
# CURSOR TENANT ISOLATION
# =============================================================================
# Cursor has its OWN tenant ID, completely separate from L's
# This prevents session state cross-contamination when Igor talks to both
#
# L uses:      L9_TENANT_ID = 'l-cto'     (in runtime/redis_client.py, core/tools/tool_graph.py)
# Cursor uses: CURSOR_TENANT_ID = 'cursor-ide' (here)
#
# They do NOT share:
# - Redis session state (short-term memory)
# - Neo4j data (Cursor doesn't use tool graph at all)
# - PostgreSQL scoped by 'agent' field in metadata
CURSOR_TENANT_ID = os.getenv("CURSOR_TENANT_ID", "cursor-ide")


# =============================================================================
# Data Models
# =============================================================================

@dataclass
class Lesson:
    """A lesson loaded from memory."""
    title: str
    severity: str
    content: str


@dataclass
class TodoItem:
    """A tracked TODO item."""
    id: str
    content: str
    status: str  # pending, in_progress, completed, cancelled
    milestone: Optional[str] = None


@dataclass
class SessionState:
    """Current session state from memory."""
    kernel_id: str
    session_id: str
    lessons: list[Lesson] = field(default_factory=list)
    todos: list[TodoItem] = field(default_factory=list)
    prompt_count: int = 0
    activated_at: Optional[datetime] = None


# =============================================================================
# Memory Operations (Docker-based with RLS Context)
# =============================================================================

# RLS Context - mirrors VPS settings
RLS_TENANT_ID = os.getenv("RLS_TENANT_ID", "l9")
RLS_ORG_ID = os.getenv("RLS_ORG_ID", "quantumai")


def _get_rls_prefix() -> str:
    """
    Generate RLS session variable SET commands.
    
    This ensures Docker Postgres mirrors VPS RLS behavior:
    - app.tenant_id: Top-level tenant isolation
    - app.org_id: Organization isolation
    - app.user_id: User isolation (cursor-ide vs l-cto)
    - app.role: Role for permission checks
    """
    return f"""
        SET app.tenant_id = '{RLS_TENANT_ID}';
        SET app.org_id = '{RLS_ORG_ID}';
        SET app.user_id = '{CURSOR_TENANT_ID}';
        SET app.role = 'cursor';
    """


def _run_psql(sql: str, with_rls: bool = True) -> Optional[str]:
    """
    Execute SQL via docker exec and return result.
    
    Args:
        sql: SQL query to execute
        with_rls: If True, set RLS session variables first (default: True)
    """
    try:
        # Prepend RLS context if requested
        if with_rls:
            full_sql = _get_rls_prefix() + sql
        else:
            full_sql = sql
            
        cmd = [
            "docker", "exec", DOCKER_POSTGRES,
            "psql", "-U", DB_USER, "-d", DATABASE,
            "-t", "-A", "-c", full_sql
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            return result.stdout.strip()
        logger.warning("psql error", stderr=result.stderr)
        return None
    except Exception as e:
        logger.error("psql failed", error=str(e))
        return None


# =============================================================================
# Neo4j Operations (with tenant isolation)
# =============================================================================

def _run_cypher(query: str, tenant_id: str = CURSOR_TENANT_ID) -> Optional[str]:
    """Execute Cypher query via docker exec with tenant filtering."""
    try:
        cmd = [
            "docker", "exec", DOCKER_NEO4J,
            "cypher-shell", "-u", NEO4J_USER, "-p", NEO4J_PASSWORD,
            query
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            return result.stdout.strip()
        logger.warning("cypher error", stderr=result.stderr)
        return None
    except Exception as e:
        logger.error("cypher failed", error=str(e))
        return None


def neo4j_query(query: str, tenant_id: str = CURSOR_TENANT_ID) -> list[dict]:
    """
    Execute Neo4j query with automatic tenant filtering.
    
    NOTE: Cursor typically does NOT use Neo4j. The tool graph is L's domain.
    These functions exist for completeness but are rarely called.
    If used, they would query Cursor's OWN tenant space (cursor-ide),
    completely separate from L's tool graph (l-cto).
    
    Injects tenant_id filter into WHERE clause.
    """
    # Inject tenant filter if not already present
    if "tenant_id" not in query.lower():
        logger.warning("neo4j_query.no_tenant_filter", query=query[:50])
    
    result = _run_cypher(query)
    if result:
        # Parse simple output (not full JSON)
        lines = result.strip().split("\n")
        if len(lines) > 1:
            headers = [h.strip() for h in lines[0].split(",")]
            rows = []
            for line in lines[1:]:
                values = [v.strip().strip('"') for v in line.split(",")]
                if len(values) == len(headers):
                    rows.append(dict(zip(headers, values)))
            return rows
    return []


def neo4j_get_agent_tools(agent_id: str, tenant_id: str = CURSOR_TENANT_ID) -> list[str]:
    """Get tools used by an agent (tenant-isolated)."""
    query = f"""
    MATCH (a:Agent {{agent_id: '{agent_id}', tenant_id: '{tenant_id}'}})-[:USES]->(t:Tool)
    WHERE t.tenant_id = '{tenant_id}'
    RETURN t.name as tool_name
    """
    rows = neo4j_query(query, tenant_id)
    return [r.get("tool_name", "") for r in rows if r.get("tool_name")]


def neo4j_get_graph_stats(tenant_id: str = CURSOR_TENANT_ID) -> dict:
    """Get graph statistics for a tenant."""
    query = f"""
    MATCH (n {{tenant_id: '{tenant_id}'}})
    RETURN labels(n)[0] as type, count(*) as count
    """
    rows = neo4j_query(query, tenant_id)
    return {r["type"]: int(r["count"]) for r in rows if r.get("type")}


# =============================================================================
# Redis Operations (with tenant key prefixing)
# =============================================================================

def _run_redis(cmd_parts: list[str]) -> Optional[str]:
    """Execute Redis command via docker exec."""
    try:
        cmd = ["docker", "exec", DOCKER_REDIS, "redis-cli"] + cmd_parts
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            return result.stdout.strip()
        logger.warning("redis error", stderr=result.stderr)
        return None
    except Exception as e:
        logger.error("redis failed", error=str(e))
        return None


def redis_key(key: str, tenant_id: str = CURSOR_TENANT_ID) -> str:
    """Generate tenant-prefixed Redis key."""
    if key.startswith(f"{tenant_id}:"):
        return key
    return f"{tenant_id}:{key}"


def redis_get(key: str, tenant_id: str = CURSOR_TENANT_ID) -> Optional[str]:
    """Get value from Redis (tenant-isolated)."""
    prefixed_key = redis_key(key, tenant_id)
    return _run_redis(["GET", prefixed_key])


def redis_set(key: str, value: str, tenant_id: str = CURSOR_TENANT_ID, ttl: int = None) -> bool:
    """Set value in Redis (tenant-isolated)."""
    prefixed_key = redis_key(key, tenant_id)
    cmd = ["SET", prefixed_key, value]
    if ttl:
        cmd.extend(["EX", str(ttl)])
    result = _run_redis(cmd)
    return result == "OK"


def redis_hset(key: str, field: str, value: str, tenant_id: str = CURSOR_TENANT_ID) -> bool:
    """Set hash field in Redis (tenant-isolated)."""
    prefixed_key = redis_key(key, tenant_id)
    result = _run_redis(["HSET", prefixed_key, field, value])
    return result is not None


def redis_hgetall(key: str, tenant_id: str = CURSOR_TENANT_ID) -> dict:
    """Get all hash fields from Redis (tenant-isolated)."""
    prefixed_key = redis_key(key, tenant_id)
    result = _run_redis(["HGETALL", prefixed_key])
    if result:
        parts = result.split("\n")
        return dict(zip(parts[::2], parts[1::2]))
    return {}


def redis_get_session_state(tenant_id: str = CURSOR_TENANT_ID) -> dict:
    """Get current session state from Redis."""
    return redis_hgetall("cursor:state:current", tenant_id)


def _run_psql_json(sql: str) -> list[dict]:
    """Execute SQL and return JSON result."""
    # Wrap query to return JSON
    json_sql = f"SELECT json_agg(t) FROM ({sql}) t;"
    result = _run_psql(json_sql)
    if result and result != "null" and result.strip():
        try:
            return json.loads(result) or []
        except json.JSONDecodeError:
            return []
    return []


def load_lessons() -> list[Lesson]:
    """
    Load LESSON packets from memory - CURSOR SCOPE ONLY.
    
    Scope Separation:
    - Cursor loads: agent = 'cursor-ide' OR no agent (legacy shared lessons)
    - L loads: agent = 'l9-standard-v1', 'l-cto', 'L' (see runtime/kernel_loader.py)
    
    This prevents L from loading Cursor's lessons and vice versa.
    """
    sql = """
        SELECT 
            envelope->'payload'->>'title' as title,
            envelope->'payload'->>'severity' as severity,
            envelope->'payload'->>'content' as content
        FROM packet_store 
        WHERE packet_type = 'LESSON'
        AND (
            envelope->'metadata'->>'agent' = 'cursor-ide'
            OR envelope->'metadata'->>'agent' IS NULL
        )
        ORDER BY 
            CASE envelope->'payload'->>'severity'
                WHEN 'ULTRA-CRITICAL' THEN 1
                WHEN 'CRITICAL' THEN 2
                WHEN 'HIGH' THEN 3
                ELSE 4
            END,
            timestamp DESC
    """
    rows = _run_psql_json(sql)
    return [Lesson(**row) for row in rows if row]


def load_todos(session_id: str) -> list[TodoItem]:
    """Load TODO items for a session."""
    sql = f"""
        SELECT envelope->'payload'->'todos' as todos
        FROM packet_store 
        WHERE packet_type = 'SESSION_TODO'
        AND envelope->'payload'->>'session_id' = '{session_id}'
        ORDER BY timestamp DESC
        LIMIT 1
    """
    rows = _run_psql_json(sql)
    if rows and rows[0] and rows[0].get('todos'):
        todos_raw = rows[0]['todos']
        if isinstance(todos_raw, str):
            todos_raw = json.loads(todos_raw)
        return [TodoItem(**t) for t in todos_raw]
    return []


def write_kernel_activation(session_id: str, kernel_id: str) -> bool:
    """Write kernel activation packet."""
    payload = {
        "kernel_id": kernel_id,
        "session_id": session_id,
        "activated_by": "cursor-ide",
        "activated_at": datetime.utcnow().isoformat(),
        "behaviors_enabled": ["todo_tracker", "confidence_logic", "execution_style", "memory_ops"]
    }
    envelope = {
        "payload": payload,
        "metadata": {
            "agent": "cursor-ide",
            "domain": "l9",
            "schema_version": "1.0.0"
        }
    }
    
    sql = f"""
        INSERT INTO packet_store (packet_id, packet_type, envelope, timestamp, scope, importance_score)
        VALUES (gen_random_uuid(), 'KERNEL_ACTIVATION', '{json.dumps(envelope)}'::jsonb, NOW(), 'shared', 1.0)
    """
    result = _run_psql(sql)
    return result is not None


def write_lesson(title: str, content: str, severity: str = "INFO", tags: list[str] = None) -> bool:
    """Write a new lesson to memory."""
    payload = {
        "title": title,
        "content": content,
        "severity": severity,
        "tags": tags or []
    }
    envelope = {
        "payload": payload,
        "metadata": {
            "agent": "cursor-ide",
            "domain": "l9",
            "schema_version": "1.0.0"
        }
    }
    
    sql = f"""
        INSERT INTO packet_store (packet_id, packet_type, envelope, timestamp, scope, importance_score)
        VALUES (gen_random_uuid(), 'LESSON', '{json.dumps(envelope)}'::jsonb, NOW(), 'shared', 0.9)
    """
    result = _run_psql(sql)
    return result is not None


def write_session_todos(session_id: str, todos: list[TodoItem]) -> bool:
    """Write/update session TODOs."""
    payload = {
        "session_id": session_id,
        "todos": [{"id": t.id, "content": t.content, "status": t.status, "milestone": t.milestone} for t in todos],
        "updated_at": datetime.utcnow().isoformat()
    }
    envelope = {
        "payload": payload,
        "metadata": {
            "agent": "cursor-ide",
            "domain": "l9",
            "schema_version": "1.0.0",
            "kernel": "l9.workflow_todo_kernel.v2"
        }
    }
    
    sql = f"""
        INSERT INTO packet_store (packet_id, packet_type, envelope, timestamp, scope, importance_score)
        VALUES (gen_random_uuid(), 'SESSION_TODO', '{json.dumps(envelope)}'::jsonb, NOW(), 'shared', 0.9)
    """
    result = _run_psql(sql)
    return result is not None


# =============================================================================
# Kernel Class
# =============================================================================

class CursorMemoryKernel:
    """
    Cursor Memory Kernel - manages session memory and behaviors.
    
    Implements l9.workflow_todo_kernel.v2.yaml behaviors:
    - Session-start lesson loading
    - TODO tracking with memory persistence
    - Confidence logic thresholds
    - Execution style preferences
    """
    
    def __init__(self, config_path: Path = KERNEL_CONFIG_PATH):
        self.config_path = config_path
        self.config: dict = {}
        self.session_state: Optional[SessionState] = None
        self.kernel_id = "l9.workflow_todo_kernel.v2"
        self._load_config()
    
    def _load_config(self) -> None:
        """Load kernel YAML configuration."""
        try:
            if self.config_path.exists():
                self.config = yaml.safe_load(self.config_path.read_text())
                logger.info("cursor_memory_kernel.config_loaded", path=str(self.config_path))
            else:
                logger.warning("cursor_memory_kernel.config_not_found", path=str(self.config_path))
                self.config = {}
        except Exception as e:
            logger.error("cursor_memory_kernel.config_load_failed", error=str(e))
            self.config = {}
    
    def activate(self, session_id: str = None) -> SessionState:
        """
        Activate kernel for a session.
        
        1. Generate session ID if not provided
        2. Write activation packet
        3. Load lessons from memory
        4. Load or create TODOs
        5. Return session state
        """
        if session_id is None:
            session_id = f"cursor-session-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}"
        
        # Write activation
        write_kernel_activation(session_id, self.kernel_id)
        
        # Load lessons
        lessons = load_lessons()
        logger.info("cursor_memory_kernel.lessons_loaded", count=len(lessons))
        
        # Load TODOs
        todos = load_todos(session_id)
        
        # Create session state
        self.session_state = SessionState(
            kernel_id=self.kernel_id,
            session_id=session_id,
            lessons=lessons,
            todos=todos,
            prompt_count=0,
            activated_at=datetime.utcnow()
        )
        
        logger.info(
            "cursor_memory_kernel.activated",
            session_id=session_id,
            lessons=len(lessons),
            todos=len(todos)
        )
        
        return self.session_state
    
    def get_lessons_summary(self) -> str:
        """Get formatted lessons summary for context injection."""
        if not self.session_state:
            return "No session active"
        
        lines = [f"## Loaded Lessons ({len(self.session_state.lessons)} total)\n"]
        
        for lesson in self.session_state.lessons:
            severity_icon = {
                "ULTRA-CRITICAL": "üî¥",
                "CRITICAL": "üî¥", 
                "HIGH": "üü†",
                "INFO": "üü¢"
            }.get(lesson.severity, "‚ö™")
            lines.append(f"- {severity_icon} **{lesson.title}**: {lesson.content[:80]}...")
        
        return "\n".join(lines)
    
    def add_todo(self, content: str, milestone: str = None) -> TodoItem:
        """Add a TODO item."""
        if not self.session_state:
            raise RuntimeError("Kernel not activated")
        
        todo = TodoItem(
            id=str(len(self.session_state.todos) + 1),
            content=content,
            status="pending",
            milestone=milestone
        )
        self.session_state.todos.append(todo)
        
        # Persist to memory
        write_session_todos(self.session_state.session_id, self.session_state.todos)
        
        return todo
    
    def complete_todo(self, todo_id: str) -> bool:
        """Mark a TODO as completed."""
        if not self.session_state:
            return False
        
        for todo in self.session_state.todos:
            if todo.id == todo_id:
                todo.status = "completed"
                write_session_todos(self.session_state.session_id, self.session_state.todos)
                return True
        return False
    
    def should_display_todos(self) -> bool:
        """Check if TODOs should be displayed based on prompt count."""
        if not self.session_state:
            return False
        
        display_interval = self.config.get("todo_tracker", {}).get("display_every_n_prompts", 3)
        return self.session_state.prompt_count % display_interval == 0
    
    def increment_prompt_count(self) -> int:
        """Increment prompt count and return new value."""
        if self.session_state:
            self.session_state.prompt_count += 1
        return self.session_state.prompt_count if self.session_state else 0
    
    def get_confidence_behavior(self, confidence: float) -> dict:
        """
        Get behavior based on confidence level.
        
        Returns dict with:
        - ask_questions: bool
        - max_questions: int
        - execute: bool
        """
        logic = self.config.get("confidence_logic", {}).get("behavior", {})
        
        if confidence >= 0.80:
            return {
                "ask_questions": False,
                "max_questions": 0,
                "execute": True,
                "band": "high"
            }
        elif confidence >= 0.50:
            return {
                "ask_questions": True,
                "max_questions": 1,
                "execute": False,
                "question_style": "high-leverage_multiple_choice",
                "band": "medium"
            }
        else:
            return {
                "ask_questions": True,
                "max_questions": 5,
                "execute": False,
                "question_style": "multi_pass_all_at_once",
                "include_suggestions": True,
                "band": "low"
            }
    
    def get_execution_style(self) -> dict:
        """Get execution style preferences."""
        return self.config.get("execution_style", {
            "voice": {"tone": "direct", "verbosity": "minimal", "no_sycophancy": True},
            "structure": {"bullets": True, "deliverables_first": True}
        })
    
    def learn(self, title: str, content: str, severity: str = "INFO") -> bool:
        """Store a new lesson in memory."""
        return write_lesson(title, content, severity)


# =============================================================================
# Factory Function (for setup-new-workspace.yaml)
# =============================================================================

_kernel_instance: Optional[CursorMemoryKernel] = None


def create_cursor_memory_kernel() -> CursorMemoryKernel:
    """
    Factory function for cursor memory kernel.
    
    Called by setup-new-workspace.yaml during session startup.
    Returns singleton instance.
    """
    global _kernel_instance
    if _kernel_instance is None:
        _kernel_instance = CursorMemoryKernel()
    return _kernel_instance


def activate_session(session_id: str = None) -> SessionState:
    """Convenience function to activate a session."""
    kernel = create_cursor_memory_kernel()
    return kernel.activate(session_id)


def get_active_kernel() -> Optional[CursorMemoryKernel]:
    """Get the active kernel instance."""
    return _kernel_instance


# =============================================================================
# CLI for Testing
# =============================================================================

if __name__ == "__main__":
    import sys
    
    kernel = create_cursor_memory_kernel()
    
    if len(sys.argv) > 1:
        cmd = sys.argv[1]
        
        if cmd == "activate":
            session_id = sys.argv[2] if len(sys.argv) > 2 else None
            state = kernel.activate(session_id)
            logger.info(f"‚úÖ Kernel activated: {state.session_id}")
            logger.info(f"   Lessons: {len(state.lessons)}")
            logger.info(f"   TODOs: {len(state.todos)}")
        
        elif cmd == "lessons":
            state = kernel.activate()
            logger.info(kernel.get_lessons_summary())
        
        elif cmd == "learn":
            title = sys.argv[2]
            content = sys.argv[3]
            severity = sys.argv[4] if len(sys.argv) > 4 else "INFO"
            if kernel.learn(title, content, severity):
                logger.info(f"‚úÖ Lesson saved: {title}")
            else:
                logger.info(f"‚ùå Failed to save lesson")
        
        else:
            logger.info(f"Unknown command: {cmd}")
            logger.info("Usage: python cursor_memory_kernel.py [activate|lessons|learn]")
    else:
        # Default: activate and show summary
        state = kernel.activate()
        logger.info(f"Session: {state.session_id}")
        logger.info(f"Lessons: {len(state.lessons)}")
        logger.info(f"TODOs: {len(state.todos)}")

